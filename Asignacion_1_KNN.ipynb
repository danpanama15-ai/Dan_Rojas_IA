{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripción del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y bioestadística, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su propósito es **predecir la aparición de diabetes tipo 2** en mujeres de origen **pima** (una población indígena del sur de Arizona, EE.UU.), a partir de diversas variables clínicas y demográficas.\n",
    "\n",
    "### Características principales:\n",
    "- **Número de registros:** 392 (en esta versión limpia, el original tenía 768).  \n",
    "- **Número de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Población:** Mujeres de al menos 21 años de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificación binaria → determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** → Número de embarazos.  \n",
    "2. **Glucose** → Concentración de glucosa en plasma después de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** → Presión arterial diastólica (mm Hg).  \n",
    "4. **SkinThickness** → Espesor del pliegue cutáneo del tríceps (mm).  \n",
    "5. **Insulin** → Nivel sérico de insulina (mu U/ml).  \n",
    "6. **BMI** → Índice de masa corporal (peso en kg / altura² en m²).  \n",
    "7. **DiabetesPedigreeFunction** → Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** → Edad en años.  \n",
    "9. **Outcome** → Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para enseñar:\n",
    "- Procesamiento y limpieza de datos biomédicos.  \n",
    "- Métodos de clasificación supervisada (KNN, regresión logística, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalización y estandarización en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17934010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Skin Thickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes Pedigree Function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>59.4</td>\n",
       "      <td>2.420</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.880</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>99</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.496</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>53.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
       "0            0      129             110              46      130  67.1   \n",
       "1            0      180              78              63       14  59.4   \n",
       "2            3      123             100              35      240  57.3   \n",
       "3            1       88              30              42       99  55.0   \n",
       "4            0      162              76              56      100  53.2   \n",
       "\n",
       "   Diabetes Pedigree Function  Age  Outcome  \n",
       "0                       0.319   26        1  \n",
       "1                       2.420   25        1  \n",
       "2                       0.880   22        0  \n",
       "3                       0.496   26        1  \n",
       "4                       0.759   25        1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento (20 muestras):\n",
      "     Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "89             1       87              68              34       77  37.6   \n",
      "173            8      155              62              26      495  34.0   \n",
      "367            4       99              76              15       51  23.2   \n",
      "296            1       89              66              23       94  28.1   \n",
      "78             2      146              76              35      194  38.2   \n",
      "52             1      128              48              45      194  40.5   \n",
      "60             5      158              84              41      210  39.4   \n",
      "30             1      103              30              38       83  43.3   \n",
      "218            4      123              80              15      176  32.0   \n",
      "93             0       95              85              25       36  37.4   \n",
      "247            2      106              64              35      119  30.5   \n",
      "91            10      148              84              48      237  37.6   \n",
      "370            3      107              62              13       48  22.9   \n",
      "124            0       84              64              22       66  35.8   \n",
      "332            7      124              70              33      215  25.5   \n",
      "172            6       98              58              33      190  34.0   \n",
      "138            4      129              86              20      270  35.1   \n",
      "7              0      165              76              43      255  47.9   \n",
      "224            5      139              80              35      160  31.6   \n",
      "25             0       94              70              27      115  43.5   \n",
      "\n",
      "     Diabetes Pedigree Function  Age  Outcome  \n",
      "89                        0.401   24        0  \n",
      "173                       0.543   46        1  \n",
      "367                       0.223   21        0  \n",
      "296                       0.167   21        0  \n",
      "78                        0.329   29        0  \n",
      "52                        0.613   24        1  \n",
      "60                        0.395   29        1  \n",
      "30                        0.183   33        0  \n",
      "218                       0.443   34        0  \n",
      "93                        0.247   24        1  \n",
      "247                       1.400   34        0  \n",
      "91                        1.001   51        1  \n",
      "370                       0.678   23        1  \n",
      "124                       0.545   21        0  \n",
      "332                       0.161   37        0  \n",
      "172                       0.430   43        0  \n",
      "138                       0.231   23        0  \n",
      "7                         0.259   26        0  \n",
      "224                       0.361   25        1  \n",
      "25                        0.347   21        0  \n",
      "\n",
      "Conjunto de testeo (20 muestras):\n",
      "     Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
      "13             6      154              78              41      140  46.1   \n",
      "369            1      109              38              18      120  23.1   \n",
      "85             2      100              54              28      105  37.8   \n",
      "317            3      129              64              29      115  26.4   \n",
      "37             0      135              68              42      250  42.3   \n",
      "96             7      102              74              40      105  37.2   \n",
      "46            17      163              72              41      114  40.9   \n",
      "248            7      160              54              32      175  30.5   \n",
      "2              3      123             100              35      240  57.3   \n",
      "155            3      170              64              37      225  34.5   \n",
      "284            1      139              46              19       83  28.7   \n",
      "188            1       77              56              30       56  33.3   \n",
      "182            2      107              74              30      100  33.6   \n",
      "387            1       92              62              25       41  19.5   \n",
      "81             3      115              66              39      140  38.1   \n",
      "129            1      119              44              47       63  35.5   \n",
      "166            9      112              82              32      175  34.2   \n",
      "267            4      173              70              14      168  29.7   \n",
      "45             7       97              76              32       91  40.9   \n",
      "228            3      100              68              23       81  31.6   \n",
      "\n",
      "     Diabetes Pedigree Function  Age  Outcome  \n",
      "13                        0.571   27        0  \n",
      "369                       0.407   26        0  \n",
      "85                        0.498   24        0  \n",
      "317                       0.219   28        1  \n",
      "37                        0.365   24        1  \n",
      "96                        0.204   45        0  \n",
      "46                        0.817   47        1  \n",
      "248                       0.588   39        1  \n",
      "2                         0.880   22        0  \n",
      "155                       0.356   30        1  \n",
      "284                       0.654   22        0  \n",
      "188                       1.251   24        0  \n",
      "182                       0.404   23        0  \n",
      "387                       0.482   25        0  \n",
      "81                        0.150   28        0  \n",
      "129                       0.280   25        0  \n",
      "166                       0.260   36        1  \n",
      "267                       0.361   33        1  \n",
      "45                        0.871   32        1  \n",
      "228                       0.949   28        0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Seleccionar 40 muestras del dataset cargado (20 para entrenamiento, 20 para testeo)\n",
    "if 'df' not in locals():\n",
    "    raise ValueError(\"El DataFrame 'df' no está definido. Asegúrate de ejecutar el Paso 1 antes de continuar.\")\n",
    "\n",
    "# Dividir el dataset en entrenamiento y testeo (20/20)\n",
    "train, test = train_test_split(df, test_size=0.5, stratify=df['Outcome'], random_state=42)\n",
    "\n",
    "# Seleccionar las primeras 20 muestras de cada conjunto\n",
    "train_subset = train.iloc[:20]\n",
    "test_subset = test.iloc[:20]\n",
    "\n",
    "print(\"Conjunto de entrenamiento (20 muestras):\")\n",
    "print(train_subset)\n",
    "print(\"\\nConjunto de testeo (20 muestras):\")\n",
    "print(test_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presión Arterial | Grosor Piel | Insulina | IMC  | Función Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7aa56bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La distancia euclidiana entre los vectores es: 26.2810\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(vector1, vector2):\n",
    "    \"\"\"Calcula la distancia euclidiana entre dos vectores.\"\"\"\n",
    "    if len(vector1) != len(vector2):\n",
    "        raise ValueError(\"Los vectores deben tener la misma longitud.\")\n",
    "    return np.sqrt(np.sum((np.array(vector1) - np.array(vector2)) ** 2))\n",
    "\n",
    "# Ejemplo de prueba\n",
    "vector_a = [1, 106, 70, 28, 135, 34.2, 0.142, 22]\n",
    "vector_b = [2, 102, 86, 36, 120, 45.5, 0.127, 23]\n",
    "\n",
    "distance = euclidean_distance(vector_a, vector_b)\n",
    "print(f\"La distancia euclidiana entre los vectores es: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89d1223c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de predicciones vs valores reales:\n",
      "\n",
      "No.   Real       Predicho   ¿Correcto?\n",
      "-----------------------------------\n",
      "1     0          0          ✓         \n",
      "2     0          0          ✓         \n",
      "3     0          0          ✓         \n",
      "4     1          0          ✗         \n",
      "5     1          0          ✗         \n",
      "6     0          0          ✓         \n",
      "7     1          0          ✗         \n",
      "8     1          1          ✓         \n",
      "9     0          0          ✓         \n",
      "10    1          1          ✓         \n",
      "11    0          0          ✓         \n",
      "12    0          0          ✓         \n",
      "13    0          0          ✓         \n",
      "14    0          1          ✗         \n",
      "15    0          0          ✓         \n",
      "16    0          0          ✓         \n",
      "17    1          0          ✗         \n",
      "18    1          0          ✗         \n",
      "19    1          0          ✗         \n",
      "20    0          0          ✓         \n",
      "\n",
      "Precisión del modelo: 65.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def knn_predict(train_data, train_labels, test_point, k=3):\n",
    "    \"\"\"\n",
    "    Predice la clase de test_point usando los k vecinos más cercanos.\n",
    "    \n",
    "    Parámetros:\n",
    "    train_data: array-like, datos de entrenamiento\n",
    "    train_labels: array-like, etiquetas de entrenamiento\n",
    "    test_point: array-like, punto a clasificar\n",
    "    k: int, número de vecinos a considerar\n",
    "    \n",
    "    Retorna:\n",
    "    int: clase predicha (0 o 1)\n",
    "    \"\"\"\n",
    "    # Calcular distancias a todos los puntos de entrenamiento\n",
    "    distances = []\n",
    "    for idx, train_point in enumerate(train_data):\n",
    "        dist = euclidean_distance(test_point, train_point)\n",
    "        distances.append((dist, train_labels[idx]))\n",
    "    \n",
    "    # Ordenar por distancia y obtener los k vecinos más cercanos\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    k_nearest = distances[:k]\n",
    "    \n",
    "    # Obtener las etiquetas de los k vecinos\n",
    "    k_nearest_labels = [label for _, label in k_nearest]\n",
    "    \n",
    "    # Votación mayoritaria\n",
    "    most_common = Counter(k_nearest_labels).most_common(1)\n",
    "    return most_common[0][0]\n",
    "\n",
    "# Verificar que tenemos los datos de entrenamiento y prueba\n",
    "if 'train_subset' not in locals() or 'test_subset' not in locals():\n",
    "    raise ValueError(\"Ejecuta el Paso 2 primero para obtener los conjuntos de entrenamiento y prueba\")\n",
    "\n",
    "# Preparar los datos\n",
    "X_train = train_subset.drop('Outcome', axis=1).values\n",
    "y_train = train_subset['Outcome'].values\n",
    "X_test = test_subset.drop('Outcome', axis=1).values\n",
    "y_test = test_subset['Outcome'].values\n",
    "\n",
    "# Realizar predicciones para cada punto de prueba\n",
    "predictions = []\n",
    "for test_point in X_test:\n",
    "    pred = knn_predict(X_train, y_train, test_point, k=3)\n",
    "    predictions.append(pred)\n",
    "\n",
    "# Crear tabla de comparación\n",
    "print(\"Comparación de predicciones vs valores reales:\")\n",
    "print(\"\\n{:<5} {:<10} {:<10} {:<10}\".format(\"No.\", \"Real\", \"Predicho\", \"¿Correcto?\"))\n",
    "print(\"-\" * 35)\n",
    "\n",
    "correct = 0\n",
    "for i, (real, pred) in enumerate(zip(y_test, predictions), 1):\n",
    "    is_correct = real == pred\n",
    "    if is_correct:\n",
    "        correct += 1\n",
    "    print(\"{:<5} {:<10} {:<10} {:<10}\".format(\n",
    "        i, real, pred, \"✓\" if is_correct else \"✗\"\n",
    "    ))\n",
    "\n",
    "# Calcular y mostrar accuracy\n",
    "accuracy = correct / len(y_test)\n",
    "print(f\"\\nPrecisión del modelo: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separación 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporción de clases usando estratificación.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e3b9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de los conjuntos de datos:\n",
      "X_train_full: (313, 8)\n",
      "X_test_full: (79, 8)\n",
      "\n",
      "Distribución de clases:\n",
      "\n",
      "Conjunto de entrenamiento:\n",
      "Outcome\n",
      "0    66.77%\n",
      "1    33.23%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Conjunto de prueba:\n",
      "Outcome\n",
      "0    67.09%\n",
      "1    32.91%\n",
      "Name: proportion, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Verificar que el dataset está cargado\n",
    "if 'df' not in locals():\n",
    "    raise ValueError(\"El DataFrame 'df' no está definido. Ejecuta el Paso 1 primero.\")\n",
    "\n",
    "# Separar features (X) y etiquetas (y)\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento (80%) y prueba (20%)\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,           # 20% para prueba\n",
    "    random_state=42,         # Para reproducibilidad\n",
    "    stratify=y               # Mantener proporción de clases\n",
    ")\n",
    "\n",
    "print(\"Dimensiones de los conjuntos de datos:\")\n",
    "print(f\"X_train_full: {X_train_full.shape}\")\n",
    "print(f\"X_test_full: {X_test_full.shape}\")\n",
    "print(\"\\nDistribución de clases:\")\n",
    "print(\"\\nConjunto de entrenamiento:\")\n",
    "print(y_train_full.value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
    "print(\"\\nConjunto de prueba:\")\n",
    "print(y_test_full.value_counts(normalize=True).mul(100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1842e010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo KNN con datos sin escalar:\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.8101\n",
      "\n",
      "Reporte de clasificación detallado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87        53\n",
      "           1       0.79      0.58      0.67        26\n",
      "\n",
      "    accuracy                           0.81        79\n",
      "   macro avg       0.80      0.75      0.77        79\n",
      "weighted avg       0.81      0.81      0.80        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Verificar que tenemos los datos necesarios\n",
    "if 'X_train_full' not in locals():\n",
    "    raise ValueError(\"Ejecuta el Paso 5 primero para obtener los conjuntos de entrenamiento y prueba\")\n",
    "\n",
    "# Crear y entrenar el modelo KNN con k=3\n",
    "knn_raw = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_raw.fit(X_train_full, y_train_full)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_raw = knn_raw.predict(X_test_full)\n",
    "\n",
    "# Calcular accuracy\n",
    "accuracy_raw = accuracy_score(y_test_full, y_pred_raw)\n",
    "\n",
    "# Guardar el resultado para la tabla comparativa\n",
    "accuracy_results = {\n",
    "    'Sin escalar': accuracy_raw\n",
    "}\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "print(\"Resultados del modelo KNN con datos sin escalar:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"Accuracy: {accuracy_raw:.4f}\")\n",
    "print(\"\\nReporte de clasificación detallado:\")\n",
    "print(classification_report(y_test_full, y_pred_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalización Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32694423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo KNN con datos normalizados (Min-Max):\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.7342\n",
      "\n",
      "Reporte de clasificación detallado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82        53\n",
      "           1       0.65      0.42      0.51        26\n",
      "\n",
      "    accuracy                           0.73        79\n",
      "   macro avg       0.70      0.65      0.66        79\n",
      "weighted avg       0.72      0.73      0.72        79\n",
      "\n",
      "\n",
      "Comparación de accuracies hasta ahora:\n",
      "Sin escalar: 0.8101\n",
      "Normalizado (Min-Max): 0.7342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Verificar que tenemos los datos necesarios\n",
    "if 'X_train_full' not in locals():\n",
    "    raise ValueError(\"Ejecuta el Paso 5 primero para obtener los conjuntos de entrenamiento y prueba\")\n",
    "\n",
    "# Crear y ajustar el normalizador Min-Max\n",
    "scaler = MinMaxScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train_full)\n",
    "X_test_normalized = scaler.transform(X_test_full)\n",
    "\n",
    "# Crear y entrenar el modelo KNN con k=3\n",
    "knn_normalized = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_normalized.fit(X_train_normalized, y_train_full)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_normalized = knn_normalized.predict(X_test_normalized)\n",
    "\n",
    "# Calcular accuracy\n",
    "accuracy_normalized = accuracy_score(y_test_full, y_pred_normalized)\n",
    "\n",
    "# Actualizar el diccionario de resultados\n",
    "accuracy_results['Normalizado (Min-Max)'] = accuracy_normalized\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "print(\"Resultados del modelo KNN con datos normalizados (Min-Max):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Accuracy: {accuracy_normalized:.4f}\")\n",
    "print(\"\\nReporte de clasificación detallado:\")\n",
    "print(classification_report(y_test_full, y_pred_normalized))\n",
    "\n",
    "# Comparar con los resultados anteriores\n",
    "print(\"\\nComparación de accuracies hasta ahora:\")\n",
    "for method, acc in accuracy_results.items():\n",
    "    print(f\"{method}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarización Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10afcc5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados del modelo KNN con datos estandarizados (Z-score):\n",
      "------------------------------------------------------------\n",
      "Accuracy: 0.7468\n",
      "\n",
      "Reporte de clasificación detallado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82        53\n",
      "           1       0.67      0.46      0.55        26\n",
      "\n",
      "    accuracy                           0.75        79\n",
      "   macro avg       0.72      0.67      0.69        79\n",
      "weighted avg       0.74      0.75      0.73        79\n",
      "\n",
      "\n",
      "Comparación final de accuracies:\n",
      "----------------------------------------\n",
      "Sin escalar................... 0.8101\n",
      "Normalizado (Min-Max)......... 0.7342\n",
      "Estandarizado (Z-score)....... 0.7468\n",
      "\n",
      "Mejor método: Sin escalar con accuracy de 0.8101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Verificar que tenemos los datos necesarios\n",
    "if 'X_train_full' not in locals():\n",
    "    raise ValueError(\"Ejecuta el Paso 5 primero para obtener los conjuntos de entrenamiento y prueba\")\n",
    "\n",
    "# Crear y ajustar el estandarizador Z-score\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train_full)\n",
    "X_test_standardized = scaler.transform(X_test_full)\n",
    "\n",
    "# Crear y entrenar el modelo KNN con k=3\n",
    "knn_standardized = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_standardized.fit(X_train_standardized, y_train_full)\n",
    "\n",
    "# Realizar predicciones\n",
    "y_pred_standardized = knn_standardized.predict(X_test_standardized)\n",
    "\n",
    "# Calcular accuracy\n",
    "accuracy_standardized = accuracy_score(y_test_full, y_pred_standardized)\n",
    "\n",
    "# Actualizar el diccionario de resultados\n",
    "accuracy_results['Estandarizado (Z-score)'] = accuracy_standardized\n",
    "\n",
    "# Mostrar resultados detallados\n",
    "print(\"Resultados del modelo KNN con datos estandarizados (Z-score):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Accuracy: {accuracy_standardized:.4f}\")\n",
    "print(\"\\nReporte de clasificación detallado:\")\n",
    "print(classification_report(y_test_full, y_pred_standardized))\n",
    "\n",
    "# Mostrar comparación final de todos los métodos\n",
    "print(\"\\nComparación final de accuracies:\")\n",
    "print(\"-\" * 40)\n",
    "for method, acc in accuracy_results.items():\n",
    "    print(f\"{method:.<30} {acc:.4f}\")\n",
    "\n",
    "# Encontrar el mejor método\n",
    "best_method = max(accuracy_results.items(), key=lambda x: x[1])\n",
    "print(f\"\\nMejor método: {best_method[0]} con accuracy de {best_method[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempeño de cada método.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e671386b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla comparativa de accuracies:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sin escalar</th>\n",
       "      <td>0.810127</td>\n",
       "      <td>81.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estandarizado (Z-score)</th>\n",
       "      <td>0.746835</td>\n",
       "      <td>74.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normalizado (Min-Max)</th>\n",
       "      <td>0.734177</td>\n",
       "      <td>73.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         accuracy  accuracy_percent\n",
       "Sin escalar              0.810127             81.01\n",
       "Estandarizado (Z-score)  0.746835             74.68\n",
       "Normalizado (Min-Max)    0.734177             73.42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Guardado: accuracy_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Verificar que accuracy_results existe\n",
    "if 'accuracy_results' not in locals():\n",
    "    raise ValueError(\"No se encontraron resultados de accuracy. Asegúrate de ejecutar los pasos anteriores.\")\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "results_df = pd.DataFrame.from_dict(accuracy_results, orient='index', columns=['accuracy'])\n",
    "results_df = results_df.sort_values('accuracy', ascending=False)\n",
    "results_df['accuracy_percent'] = (results_df['accuracy'] * 100).round(2)\n",
    "\n",
    "# Mostrar tabla\n",
    "print(\"Tabla comparativa de accuracies:\")\n",
    "display(results_df)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(8, 4))\n",
    "results_df['accuracy'].plot(kind='barh', color=['#2ca02c', '#1f77b4', '#ff7f0e'])\n",
    "plt.xlim(0, 1)\n",
    "plt.xlabel('Accuracy')\n",
    "plt.title('Comparación de Accuracy entre métodos')\n",
    "for i, (name, row) in enumerate(results_df.iterrows()):\n",
    "    plt.text(row['accuracy'] + 0.01, i, f\"{row['accuracy_percent']}%\", va='center')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Guardar CSV\n",
    "results_df.to_csv('accuracy_comparison.csv', index=True)\n",
    "print('\\nGuardado: accuracy_comparison.csv')\n",
    "\n",
    "# Marcar la tarea 1 como completada en la lista TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "767a71c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instalando matplotlib...\n",
      "Instalación completada. Reinicia el kernel si es necesario.\n",
      "Instalación completada. Reinicia el kernel si es necesario.\n"
     ]
    }
   ],
   "source": [
    "# Instalar matplotlib si no está presente (ejecutar una vez)\n",
    "# Nota: en muchos kernels de Jupyter se puede usar `%pip install matplotlib`.\n",
    "# Si tu entorno no permite instalaciones desde aquí, ejecuta en una celda nueva:\n",
    "# %pip install matplotlib\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    import matplotlib\n",
    "except ModuleNotFoundError:\n",
    "    print('Instalando matplotlib...')\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'matplotlib'])\n",
    "    print('Instalación completada. Reinicia el kernel si es necesario.')\n",
    "else:\n",
    "    print('matplotlib ya está instalado')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexión y aplicación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "1. ¿Por qué es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "La normalización o estandarización es importante porque KNN se basa en distancias: si una característica tiene una escala mucho mayor que las demás, dominará el cálculo de la distancia y sesgará las predicciones. Normalizar/Z-score ponen las features en la misma escala para que todas contribuyan de forma equilibrada.\n",
    "\n",
    "- Min‑Max: escala a [0,1], útil cuando se requiere un rango fijo; sensible a outliers.\n",
    "- Z‑score: centra en 0 y escala por desviación estándar; más robusto si las distribuciones tienen medias distintas.\n",
    "\n",
    "Regla práctica: siempre probar ambos (o usar pipeline + validación cruzada) y elegir con base en la métrica. También hay que escalar usando parámetros del conjunto de entrenamiento y aplicar los mismos al test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "2. ¿Qué diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "En tu experimento obtuviste:\n",
    "\n",
    "- Sin escalar → 81.01% (mejor)\n",
    "- Estandarizado (Z‑score) → 74.68%\n",
    "- Normalizado (Min‑Max) → 73.42%\n",
    "\n",
    "Interpretación: aquí el escalado redujo ligeramente el rendimiento. Posibles causas:\n",
    "- Las magnitudes originales de las features contenían señal discriminativa que al escalar se atenuó.\n",
    "- Outliers o la forma de las distribuciones hicieron que Min‑Max o Z‑score empeoraran la separación entre clases.\n",
    "\n",
    "Recomendación: usar validación cruzada para comparar combinaciones (k, tipo de escalado, métrica) antes de decidir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "3. Si aumentamos el valor de **k** (número de vecinos), ¿cómo crees que cambiaría el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "Efecto esperado al aumentar k:\n",
    "\n",
    "- k pequeño → baja sesgo y alta varianza (modelo sensible al ruido y posible sobreajuste).\n",
    "- k grande → mayor sesgo y menor varianza (decisiones más suaves; posible subajuste).\n",
    "\n",
    "Consejos prácticos:\n",
    "- Elegir k por validación cruzada (buscar el punto con mejor trade‑off).\n",
    "- Usar k impar en problemas binarios para evitar empates.\n",
    "- Considerar votación ponderada por distancia (vecinos cercanos pesan más) en vez de sólo aumentar k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "4. ¿Qué ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "Ventajas de implementar KNN manualmente antes de usar scikit‑learn:\n",
    "\n",
    "- Entendimiento: aprendes cómo se calculan distancias y cómo influyen el preprocesado y la elección de k.\n",
    "- Depuración: puedes inspeccionar distancias y vecinos concretos para diagnosticar errores o sesgos.\n",
    "- Flexibilidad educativa: probar variantes (distancias custom, votación ponderada, selección de features) sin abstracciones.\n",
    "\n",
    "Nota: para producción, scikit‑learn es más eficiente y ofrece optimizaciones (KD‑trees, Ball‑trees, búsquedas aproximadas).\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "5. ¿Qué limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "Limitaciones de KNN en datasets grandes o de alta dimensionalidad:\n",
    "\n",
    "- Computacional: la predicción es costosa (compara con todos los ejemplos de entrenamiento). Requiere mucho espacio y tiempo.\n",
    "- Curse of dimensionality: en muchas dimensiones las distancias se vuelven menos informativas y la discriminación empeora.\n",
    "- Sensible a features irrelevantes y al escalado.\n",
    "\n",
    "Mitigaciones:\n",
    "- Reducción de dimensionalidad (PCA, selección de features).\n",
    "- Vecinos aproximados (FAISS, Annoy) o estructuras de búsqueda (KD‑tree/ Ball‑tree).\n",
    "- Modelos alternativos (Random Forest, Logistic Regression) si el dataset es muy grande."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación: Práctica KNN\n",
    "\n",
    "| Criterio | Descripción | Puntaje Máximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploración del dataset** | Carga correcta del archivo CSV, explicación de las variables y verificación de datos. | 15 pts |\n",
    "| **2. Implementación manual de KNN** | Código propio para calcular distancias euclidianas, selección de vecinos y votación mayoritaria. | 20 pts |\n",
    "| **3. Predicción individual (ejemplo aleatorio)** | Explicación clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluación con `train_test_split`, comparación con el método manual. | 15 pts |\n",
    "| **5. Normalización y estandarización** | Aplicación correcta de Min-Max y Z-score, con cálculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentación clara de los resultados y comparación entre métodos. | 10 pts |\n",
    "| **7. Reflexión y preguntas finales** | Respuestas a las preguntas de análisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
